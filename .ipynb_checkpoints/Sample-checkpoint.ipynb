{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tf_retinanet\n",
    "from tf_retinanet.builders import application_builder\n",
    "from tf_retinanet.builders import loss_builder\n",
    "from tf_retinanet.builders import sample_builder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset():\n",
    "    labels = pd.read_csv(os.path.join('head', 'labels.csv'))\n",
    "    annotations = pd.read_csv(os.path.join('head', 'boxes.csv'))\n",
    "    annotations['classes'] = tf_retinanet.to_classes(annotations['name'].values)\n",
    "    with tf_retinanet.data.Shards(os.path.join('data', 'dataset.record')) as shards:\n",
    "        for index, label in tqdm(labels.iterrows()):\n",
    "            path = os.path.join('head', 'images', label['filename'])\n",
    "            image = tf_retinanet.image.read(path)\n",
    "            _annotations = annotations[annotations['image_id'] == label['id']]\n",
    "            bbox = _annotations[['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "            image, bbox = tf_retinanet.transform(image, bbox.values, min_side=200, max_side=300)\n",
    "\n",
    "            # create batch, batch_size=1\n",
    "            classes = np.zeros(shape=(1, _annotations['classes'].values.shape[0], 1))\n",
    "            classes[0, :, 0] = _annotations['classes'].values\n",
    "            bboxses = np.zeros(shape=(1,) + bbox.shape)\n",
    "            bboxses[0, :] = bbox\n",
    "            images = np.zeros(shape=(1,) + image.shape)\n",
    "            images[0, :] = image\n",
    "\n",
    "            sample = sample_builder.build(images, bboxses, classes, 1)\n",
    "            shards.write(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2404it [02:40, 14.98it/s]\n"
     ]
    }
   ],
   "source": [
    "build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf_retinanet.data.read(os.path.join('data', 'dataset.record-?????-of-00010'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = application_builder.build('mobilenet_v1', num_classes=1, num_anchors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "model.compile(optiomizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
    "             loss=[loss_builder.build_smooth_l1_loss(), loss_builder.build_focal_loss()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(dataset):\n",
    "    while True:\n",
    "        dataset = dataset.shuffle(1000)\n",
    "        for image, bboxes, classes in dataset:\n",
    "            yield (image, [bboxes, classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 575s 575ms/step - loss: 5.9981 - localization_loss: 2.6393 - classification_loss: 3.3588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a5a25d97f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(input_fn(dataset), steps_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance for 10 examples: 0.749924898147583\n",
      "performance for last example: 0.062482357025146484\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "at = time()\n",
    "for image, _, _ in dataset.take(10):\n",
    "    st = time()\n",
    "    bboxes, classes = model(image)\n",
    "et = time()\n",
    "print('performance for 10 examples:', et - at)\n",
    "print('performance for last example:', et - st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
